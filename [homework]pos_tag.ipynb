{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[homework]pos_tag.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Antekov/book-isob/blob/master/%5Bhomework%5Dpos_tag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMohh_6CwC4W"
      },
      "source": [
        "### Задача определения частей речи, Part-Of-Speech Tagger (POS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Aad2tmBwC4Y"
      },
      "source": [
        "Мы будем решать задачу определения частей речи (POS-теггинга)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYYV0mdmwC4f",
        "scrolled": false
      },
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import brown\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPgI52lRwC4n"
      },
      "source": [
        "Вам в помощь http://www.nltk.org/book/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxdJxMEAwC4o"
      },
      "source": [
        "Загрузим brown корпус"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvhXAL_9wC4q",
        "scrolled": true
      },
      "source": [
        "nltk.download('brown')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wto8PSC6wC4v"
      },
      "source": [
        "<b>Существует не одна система тегирования, поэтому будьте внимательны, когда прогнозируете тег слов в тексте и вычисляете качество прогноза. Можете получить несправедливо низкое качество вашего решения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ6tuHA_wC4z"
      },
      "source": [
        "Cейчас будем использовать универсальную систему тегирования universal_tagset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cht7dImWwC42"
      },
      "source": [
        "nltk.download('universal_tagset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiTimRRywC47"
      },
      "source": [
        "<img src=\"https://4.bp.blogspot.com/-IcFli2wljs0/WrVCw3umY_I/AAAAAAAACYM/UJ_neoUAs3wF95dj2Ouf3BzxXzB_b2TbQCLcBGAs/s1600/postags.png\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyDBMcBSwC48"
      },
      "source": [
        "Мы имеем массив предложений пар (слово-тег)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BobflewQwC4-",
        "scrolled": false
      },
      "source": [
        "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")\n",
        "brown_tagged_sents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSu1KqRrwC5L"
      },
      "source": [
        "Первое предложение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCHCZPlkwC5N"
      },
      "source": [
        "brown_tagged_sents[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIV2MiRxwC5Q"
      },
      "source": [
        "Все пары (слово-тег)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVx9e9HcwC5R"
      },
      "source": [
        "brown_tagged_words = brown.tagged_words(tagset='universal')\n",
        "brown_tagged_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-ADby6LwC5V"
      },
      "source": [
        "Проанализируйте данные, с которыми Вы работаете. Используйте `nltk.FreqDist()` для подсчета частоты встречаемости тега и слова в нашем корпусе. Под частой элемента подразумевается кол-во этого элемента в корпусе."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "JzRoXuKFcMZK"
      },
      "source": [
        "# Приведем слова к нижнему регистру\n",
        "brown_tagged_words = list(map(lambda x: (x[0].lower(), x[1]), brown_tagged_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4giWaqXjwC5W"
      },
      "source": [
        "print('Кол-во предложений: ', len(brown_tagged_sents))\n",
        "tags = [tag for (word, tag) in brown_tagged_words] # наши теги\n",
        "words = [word for (word, tag) in brown_tagged_words] # наши слова\n",
        "\n",
        "tag_num = pd.Series('''your code''').sort_values(ascending=False) # тег - кол-во тега в корпусе\n",
        "word_num = pd.Series('''your code''').sort_values(ascending=False) # слово - кол-во слова в корпусе"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfiPpCcLwC5Z",
        "scrolled": true
      },
      "source": [
        "tag_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y1huw7TwC5b"
      },
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.bar(tag_num.index, tag_num.values)\n",
        "plt.title(\"Tag_frequency\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBbhnJsmwC5f"
      },
      "source": [
        "word_num[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WmEOBMkwC5i"
      },
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.bar(word_num.index[:10], word_num.values[:10])\n",
        "plt.title(\"Word_frequency\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n08z2PjMwC5o"
      },
      "source": [
        "### Вопрос 1:\n",
        "* Кол-во слова `cat` в корпусе? **(0.5 балл)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhB7di3YwC5p"
      },
      "source": [
        "'''your code'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsCfVLsewC5s"
      },
      "source": [
        "### Вопрос 2:\n",
        "* Самое популярное слово с самым популярным тегом? **(0.5 балл)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oio-XBYkwC5t"
      },
      "source": [
        "# Выбираем сначала слова с самым популярным тегом, а затем среди них выбираем самое популярное слово.\n",
        "'''your code'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f1rl5x0wC55"
      },
      "source": [
        "Cделайте разбиение выборки на обучение и контроль в отношении 9:1. **(0.5 балл)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX9t-1qowC58"
      },
      "source": [
        "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")\n",
        "# Приведем слова к нижнему регистру\n",
        "my_brown_tagged_sents = []\n",
        "for sent in brown_tagged_sents:\n",
        "    my_brown_tagged_sents.append(list(map(lambda x: (x[0].lower(), x[1]), sent)))\n",
        "my_brown_tagged_sents = np.array(my_brown_tagged_sents)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_sents, test_sents = train_test_split('''your code''', random_state=0,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXkVwUjYwC5-"
      },
      "source": [
        "len(train_sents), len(test_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpAgfZRTwC6h"
      },
      "source": [
        "## DefaultTagger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b4cPKyiwC6j"
      },
      "source": [
        "### Вопрос 3:\n",
        "* Какое качество вы бы получили, если бы предсказывали любой тег, как самый популярный тег на выборке train(округлите до одного знака после запятой)? **(0.5 балл)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td-0Pe0vwC6k"
      },
      "source": [
        "Вы можете использовать DefaultTagger(метод tag для предсказания частей речи предложения)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfZYlMxJwC6m"
      },
      "source": [
        "from nltk.tag import DefaultTagger\n",
        "default_tagger = DefaultTagger('''your code''')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CXKibo_cMcB"
      },
      "source": [
        "true_pred = 0\n",
        "num_pred = 0\n",
        "\n",
        "for sent in test_sents:\n",
        "    tags = np.array([tag for (word, tag) in sent])\n",
        "    words = np.array([word for (word, tag) in sent])\n",
        "    \n",
        "    tagged_sent = default_tagger.tag(words)\n",
        "    outputs = [tag for token, tag in tagged_sent]\n",
        "    \n",
        "    true_pred += '''your code'''\n",
        "    num_pred += len(words)\n",
        "    \n",
        "print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w1W5hSkcMcV"
      },
      "source": [
        "## LSTMTagger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm1-S3t2cMcW"
      },
      "source": [
        "### Подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GayTl7mUcMcX"
      },
      "source": [
        "Изменим структуру данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnXcI64fxoj4",
        "scrolled": false
      },
      "source": [
        "pos_data = [list(zip(*sent)) for sent in brown_tagged_sents]\n",
        "print(pos_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpRE3c-3cMcc"
      },
      "source": [
        "Пора эксплуатировать pytorch!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvFlzrYnxokE"
      },
      "source": [
        "from torchtext.data import Field, BucketIterator\n",
        "import torchtext\n",
        "\n",
        "# наши поля\n",
        "WORD = Field(lower=True)\n",
        "TAG = Field(unk_token=None) # все токены нам извсетны\n",
        "\n",
        "# создаем примеры\n",
        "examples = []\n",
        "for words, tags in pos_data:\n",
        "    examples.append(torchtext.data.Example.fromlist([list(words), list(tags)], fields=[('words', WORD), ('tags', TAG)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjl6u6cpOc1u"
      },
      "source": [
        "Вот один наш пример:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnrzktytN9rL"
      },
      "source": [
        "print(vars(examples[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUhTrWCWcMcj"
      },
      "source": [
        "Теперь формируем наш датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGKkbZUIxokO",
        "scrolled": true
      },
      "source": [
        "# кладем примеры в наш датасет\n",
        "dataset = torchtext.data.Dataset(examples, fields=[('words', WORD), ('tags', TAG)])\n",
        "\n",
        "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.1, 0.1])\n",
        "\n",
        "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T89unpppcMcp"
      },
      "source": [
        "Построим словари. Параметр `min_freq` выберете сами. При построении словаря испольузем только **train** **(0.5 балл)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZwkwhlrxoka",
        "scrolled": true
      },
      "source": [
        "WORD.build_vocab('''your code''', min_freq='''your code''')\n",
        "TAG.build_vocab('''your code''')\n",
        "\n",
        "print(f\"Unique tokens in source (ru) vocabulary: {len(WORD.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(TAG.vocab)}\")\n",
        "\n",
        "print(WORD.vocab.itos[::200])\n",
        "print(TAG.vocab.itos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESwY5AZ9QKiv"
      },
      "source": [
        "Здесь вы увидете токен `unk` и `pad`. Первый служит для обозначения слов, которых у нас нет в словаре. Второй служит для того, что объекты в одном батче были одинакового размера."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjn07NP-xokl",
        "scrolled": true
      },
      "source": [
        "print(vars(train_data.examples[9]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxgkU4cZcMcz"
      },
      "source": [
        "Посмотрим с насколько большими предложениями мы имеем дело"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVpMi1_0xoku",
        "scrolled": true
      },
      "source": [
        "length = map(len, [vars(x)['words'] for x in train_data.examples])\n",
        "\n",
        "plt.figure(figsize=[8, 4])\n",
        "plt.title(\"Length distribution in Train data\")\n",
        "plt.hist(list(length), bins=20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi28N2RBcMc5"
      },
      "source": [
        "Для обучения `LSTM` лучше использовать colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAGSrqWsxok2",
        "scrolled": true
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DSWm0UjcMc-"
      },
      "source": [
        "Для более быстрого и устойчивого обучения сгруппируем наши данные по батчам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmwAyhNgxok_"
      },
      "source": [
        "# бьем нашу выборку на батч, не забывая сначала отсортировать выборку по длине\n",
        "def _len_sort_key(x):\n",
        "    return len(x.words)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device,\n",
        "    sort_key=_len_sort_key\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aTjW00nxolI"
      },
      "source": [
        "# посморим  на количество батчей\n",
        "list(map(len, [train_iterator, valid_iterator, test_iterator]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyLQsizhcMdI"
      },
      "source": [
        "### Модель и её обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i9oHzcrcMdJ"
      },
      "source": [
        "Инициализируем нашу модель. Прочитайте про dropout [тут](https://habr.com/ru/company/wunderfund/blog/330814/). **(3 балла)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff7BLWs_xolS",
        "scrolled": true
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, output_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "  \n",
        "        self.embeddings = '''your code'''\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "        self.rnn = nn.LSTM('''your code''')\n",
        "        self.tag = nn.Linear(hid_dim, output_dim)\n",
        "\n",
        "    def forward(self, sent):\n",
        "        \n",
        "        #sent = [sent len, batch size] \n",
        "        \n",
        "        # не забываем применить dropout к embedding\n",
        "        embedded = self.dropout('''your code''')\n",
        "\n",
        "        output, _ = self.rnn(embedded)\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "\n",
        "        prediction = self.tag('''your code''')\n",
        "    \n",
        "        return prediction\n",
        "        \n",
        "# параметры модели\n",
        "INPUT_DIM = len(WORD.vocab)\n",
        "OUTPUT_DIM = len(TAG.vocab)\n",
        "EMB_DIM = '''your code'''\n",
        "HID_DIM = '''your code'''\n",
        "DROPOUT = 0.5\n",
        "\n",
        "model = LSTMTagger('''your code''').to(device)\n",
        "\n",
        "# инициализируем веса\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJLqq8IHcMdQ"
      },
      "source": [
        "Подсчитаем количество обучаемых параметров нашей модели. Используйте метод `numel()`. **(1 балл)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Auu53Kdxolm"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return '''your code'''\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSBfvf9HcMd9"
      },
      "source": [
        "Погнали обучать **(2 балла)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjD1Y7Rmxolu",
        "scrolled": true
      },
      "source": [
        "PAD_IDX = TAG.vocab.stoi['<pad>']\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None):\n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    history = []\n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        words = '''your code'''\n",
        "        tags = '''your code'''\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model('''your code''')\n",
        "        \n",
        "        #tags = [sent len, batch size]\n",
        "        #output = [sent len, batch size, output dim]\n",
        "        \n",
        "        output = '''your code'''\n",
        "        tags = tags.view(-1)\n",
        "        \n",
        "        #tags = [sent len * batch size]\n",
        "        #output = [sent len * batch size, output dim]\n",
        "        \n",
        "        loss = criterion('''your code''')\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        # Gradient clipping(решение проблемы взрыва граденты), clip - максимальная норма вектора\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "        history.append(loss.cpu().data.numpy())\n",
        "        if (i+1)%10==0:\n",
        "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
        "\n",
        "            clear_output(True)\n",
        "            ax[0].plot(history, label='train loss')\n",
        "            ax[0].set_xlabel('Batch')\n",
        "            ax[0].set_title('Train loss')\n",
        "            \n",
        "            if train_history is not None:\n",
        "                ax[1].plot(train_history, label='general train history')\n",
        "                ax[1].set_xlabel('Epoch')\n",
        "            if valid_history is not None:\n",
        "                ax[1].plot(valid_history, label='general valid history')\n",
        "            plt.legend()\n",
        "            \n",
        "            plt.show()\n",
        "\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    history = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            words = '''your code'''\n",
        "            tags = '''your code'''\n",
        "\n",
        "            output = model('''your code''')\n",
        "\n",
        "            #tags = [sent len, batch size]\n",
        "            #output = [sent len, batch size, output dim]\n",
        "\n",
        "            output = '''your code'''\n",
        "            tags = tags.view(-1)\n",
        "\n",
        "            #tags = [sent len * batch size]\n",
        "            #output = [sent len * batch size, output dim]\n",
        "\n",
        "            loss = criterion('''your code''')\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJdXIyTHxol2",
        "scrolled": false
      },
      "source": [
        "import time\n",
        "import math\n",
        "import matplotlib\n",
        "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import clear_output\n",
        "\n",
        "train_history = []\n",
        "valid_history = []\n",
        "\n",
        "N_EPOCHS = '''your code'''\n",
        "CLIP = '''your code'''\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'best-val-model.pt')\n",
        "\n",
        "    train_history.append(train_loss)\n",
        "    valid_history.append(valid_loss)\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr860UPacMeI"
      },
      "source": [
        "### Применение модели\n",
        " **(1 балл)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sDAfAq9xol9"
      },
      "source": [
        "def accuracy_model(model, iterator):\n",
        "    model.eval()\n",
        "    \n",
        "    true_pred = 0\n",
        "    num_pred = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "           '''your code'''\n",
        "\n",
        "            output = model('''your code''')\n",
        "            \n",
        "            #output = [sent len, batch size, output dim]\n",
        "            # Выбираем для каждого слова индекс тэга с максимальной вероятностью\n",
        "            output = '''your code'''\n",
        "            \n",
        "            #output = [sent len, batch size]\n",
        "            predict_tags = output.cpu().numpy()\n",
        "            true_tags = tags.cpu().numpy()\n",
        "\n",
        "            true_pred += np.sum((true_tags == predict_tags) & (true_tags != PAD_IDX))\n",
        "            num_pred += np.prod(true_tags.shape) - (true_tags == PAD_IDX).sum()\n",
        "        \n",
        "    return round(true_pred / num_pred * 100, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2n0H85mxomE",
        "scrolled": true
      },
      "source": [
        "print(\"Accuracy:\", accuracy_model(model, test_iterator), '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FacTKSPJcMeP"
      },
      "source": [
        "Вы можете улучшить качество, изменяя параметры модели. Вам неоходимо добиться качества не меньше, чем `accuracy = 92 %`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqD1lZuwxomK",
        "scrolled": true
      },
      "source": [
        "best_model = LSTMTagger(INPUT_DIM, EMB_DIM, HID_DIM, OUTPUT_DIM, DROPOUT).to(device)\n",
        "best_model.load_state_dict(torch.load('best-val-model.pt'))\n",
        "assert accuracy_model(best_model, test_iterator) >= 92"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqnaeXi6sKl5"
      },
      "source": [
        "### **Если качество сети меньше 92 процентов, то снимается половина от всех полученных баллов .<br> То есть максимум в этом случае 5 баллов за работу.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVfdJM-lcMeZ"
      },
      "source": [
        "Пример решение нашей задачи:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3GUbwldxomW"
      },
      "source": [
        "def print_tags(model, data):\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        words, _ = data\n",
        "        example = torch.LongTensor([WORD.vocab.stoi[elem] for elem in words]).unsqueeze(1).to(device)\n",
        "        \n",
        "        output = model(example).argmax(dim=-1).cpu().numpy()\n",
        "        tags = [TAG.vocab.itos[int(elem)] for elem in output]\n",
        "\n",
        "        for token, tag in zip(words, tags):\n",
        "            print(f'{token:15s}{tag}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "4mQoHc_EcMed"
      },
      "source": [
        "print_tags(model, pos_data[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "zMIJDOBmwC6v"
      },
      "source": [
        "## Вывод: \n",
        "**(0.5 балл)**"
      ]
    }
  ]
}